[2025-09-17 20:30:56.788] [4841] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 20:30:56.801] [4841] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 20:30:56.803] [4841] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 20:30:56.803] [4841] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 20:30:56.805] [4841] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:30:56.805] [4841] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:30:56.810] [4841] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 20:30:56.811] [4841] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 20:30:56.811] [4841] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 8.358988 milliseconds
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 8.653321 milliseconds
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:30:56.814] [4841] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 4868)
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 4869)
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 4870)
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 20:30:56.815] [4841] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 20:44:05.108] [1972] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 20:44:05.129] [1972] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 20:44:05.131] [1972] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 20:44:05.132] [1972] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 20:44:05.162] [1972] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:44:05.163] [1972] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:44:05.172] [1972] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 20:44:05.172] [1972] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 20:44:05.172] [1972] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 20:44:05.175] [1972] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 11.171657 milliseconds
[2025-09-17 20:44:05.175] [1972] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 11.809164 milliseconds
[2025-09-17 20:44:05.175] [1972] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 20:44:05.177] [1972] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 1991)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 1992)
[2025-09-17 20:44:05.178] [1972] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 20:44:05.180] [1972] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outpu[2025-09-17 20:44:46.423] [2033] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 20:44:46.435] [2033] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 20:44:46.436] [2033] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 20:44:46.436] [2033] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 20:44:46.438] [2033] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:44:46.438] [2033] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:44:46.444] [2033] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 20:44:46.444] [2033] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 20:44:46.444] [2033] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 20:44:46.446] [2033] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 7.567603 milliseconds
[2025-09-17 20:44:46.446] [2033] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 7.817737 milliseconds
[2025-09-17 20:44:46.446] [2033] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 20:44:46.446] [2033] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 2050)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2051)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 2052)
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 20:44:46.447] [2033] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 20:56:20.619] [2548] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 20:56:20.630] [2548] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 20:56:20.632] [2548] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 20:56:20.632] [2548] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 20:56:20.634] [2548] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:56:20.634] [2548] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 20:56:20.640] [2548] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 20:56:20.640] [2548] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 20:56:20.640] [2548] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 20:56:20.643] [2548] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 8.228904 milliseconds
[2025-09-17 20:56:20.643] [2548] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 8.584388 milliseconds
[2025-09-17 20:56:20.643] [2548] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 20:56:20.643] [2548] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 20:56:20.644] [2548] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:56:20.644] [2548] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 2575)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2576)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 2577)
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 20:56:20.645] [2548] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 21:01:20.388] [2781] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 21:01:20.400] [2781] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 21:01:20.402] [2781] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 21:01:20.403] [2781] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 21:01:20.406] [2781] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:01:20.406] [2781] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:01:20.413] [2781] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 21:01:20.413] [2781] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 21:01:20.413] [2781] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 9.281389 milliseconds
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 9.624611 milliseconds
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 21:01:20.416] [2781] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 2808)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 2809)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 2810)
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 21:01:20.417] [2781] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 21:10:34.616] [3091] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 21:10:34.628] [3091] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 21:10:34.630] [3091] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 21:10:34.630] [3091] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 21:10:34.633] [3091] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:10:34.633] [3091] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:10:34.641] [3091] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 21:10:34.641] [3091] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 21:10:34.641] [3091] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 12.31345 milliseconds
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 12.605674 milliseconds
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 3121)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 3122)
[2025-09-17 21:10:34.646] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 21:10:34.647] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 3123)
[2025-09-17 21:10:34.647] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 21:10:34.647] [3091] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl0AsyncHwEl was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl1nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl1nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:10:48.746] [3091] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl0AsyncHwEl has 0 frames in his Queue on destruction
[2025-09-17 21:15:07.778] [3235] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 21:15:07.789] [3235] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 21:15:07.791] [3235] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 21:15:07.791] [3235] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 21:15:07.793] [3235] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:15:07.793] [3235] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:15:07.800] [3235] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 21:15:07.800] [3235] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 21:15:07.800] [3235] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 9.663031 milliseconds
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 9.959681 milliseconds
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 3262)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 3263)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 3264)
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 21:15:07.804] [3235] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl0AsyncHwEl was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl1nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl1nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:15:24.371] [3235] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl0AsyncHwEl has 0 frames in his Queue on destruction
[2025-09-17 21:16:17.914] [3385] [HailoRT] [info] [vdevice.cpp:523] [create] Creating vdevice with params: device_count: 1, scheduling_algorithm: ROUND_ROBIN, multi_process_service: false
[2025-09-17 21:16:17.926] [3385] [HailoRT] [info] [device.cpp:49] [Device] OS Version: Linux 6.6.62+rpt-rpi-2712 #1 SMP PREEMPT Debian 1:6.6.62-1+rpt1 (2024-11-25) aarch64
[2025-09-17 21:16:17.928] [3385] [HailoRT] [info] [control.cpp:108] [control__parse_identify_results] firmware_version is: 4.20.0
[2025-09-17 21:16:17.928] [3385] [HailoRT] [info] [vdevice.cpp:651] [create] VDevice Infos: 0000:01:00.0
[2025-09-17 21:16:17.930] [3385] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:16:17.930] [3385] [HailoRT] [info] [hef.cpp:1929] [get_network_group_and_network_name] No name was given. Addressing all networks of default network_group: nvidia_model
[2025-09-17 21:16:17.937] [3385] [HailoRT] [info] [buffer_requirements.cpp:195] [find_initial_desc_page_size] Using non-default initial_desc_page_size of 64, due to a small transfer size (8)
[2025-09-17 21:16:17.937] [3385] [HailoRT] [info] [internal_buffer_manager.cpp:202] [print_execution_results] Default Internal buffer planner failed to meet requirements
[2025-09-17 21:16:17.937] [3385] [HailoRT] [info] [internal_buffer_manager.cpp:212] [print_execution_results] Default Internal buffer planner executed successfully
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [device_internal.cpp:57] [configure] Configuring HEF took 8.559309 milliseconds
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [vdevice.cpp:749] [configure] Configuring HEF on VDevice took 8.912143 milliseconds
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [infer_model.cpp:436] [configure] Configuring network group 'nvidia_model' with params: batch size: 0, power mode: PERFORMANCE, latency: NONE
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [multi_io_elements.cpp:756] [create] Created (AsyncHwEl)
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (EntryPushQEl0nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:16:17.940] [3385] [HailoRT] [info] [filter_elements.cpp:101] [create] Created (PreInferEl1nvidia_model/input_layer1 | Quantization - src_type: FLOAT32, dst_type UINT8, limvals_min: 0, limvals_max: 1)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl1nvidia_model/input_layer1 | timeout: 10s)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [queue_elements.cpp:450] [create] Created (PushQEl0AsyncHwEl | timeout: 10s)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [filter_elements.cpp:375] [create] Created (PostInferEl0AsyncHwEl | Quantization - src_type: UINT8, dst_type FLOAT32, limvals_min: -0.817795, limvals_max: 1.18738 | Padding Periph shape - src_shape: (1, 1, 1), dst_shape: (1, 1, 1))
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [edge_elements.cpp:187] [create] Created (LastAsyncEl0PostInferEl0AsyncHwEl)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] EntryPushQEl0nvidia_model/input_layer1 | inputs: user | outputs: PreInferEl1nvidia_model/input_layer1(running in thread_id: 3412)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PreInferEl1nvidia_model/input_layer1 | inputs: EntryPushQEl0nvidia_model/input_layer1[0] | outputs: PushQEl1nvidia_model/input_layer1
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl1nvidia_model/input_layer1 | inputs: PreInferEl1nvidia_model/input_layer1[0] | outputs: AsyncHwEl(running in thread_id: 3413)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] AsyncHwEl | inputs: PushQEl1nvidia_model/input_layer1[0] | outputs: PushQEl0AsyncHwEl
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PushQEl0AsyncHwEl | inputs: AsyncHwEl[0] | outputs: PostInferEl0AsyncHwEl(running in thread_id: 3414)
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] PostInferEl0AsyncHwEl | inputs: PushQEl0AsyncHwEl[0] | outputs: LastAsyncEl0PostInferEl0AsyncHwEl
[2025-09-17 21:16:17.941] [3385] [HailoRT] [info] [pipeline.cpp:891] [print_deep_description] LastAsyncEl0PostInferEl0AsyncHwEl | inputs: PostInferEl0AsyncHwEl[0] | outputs: user
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [async_infer_runner.cpp:86] [shutdown] Pipeline was aborted. Shutting it down
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl0AsyncHwEl was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element PushQEl1nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:570] [execute_deactivate] enqueue() in element EntryPushQEl0nvidia_model/input_layer1 was aborted, got status = HAILO_SHUTDOWN_EVENT_SIGNALED(57)
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element EntryPushQEl0nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl1nvidia_model/input_layer1 has 0 frames in his Queue on destruction
[2025-09-17 21:16:25.157] [3385] [HailoRT] [info] [queue_elements.cpp:46] [~BaseQueueElement] Queue element PushQEl0AsyncHwEl has 0 frames in his Queue on destruction
