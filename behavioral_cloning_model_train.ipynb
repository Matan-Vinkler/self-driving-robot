{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matan-Vinkler/self-driving-robot/blob/main/behavioral_cloning_model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training on Behavioral Cloning Approach\n",
        "\n",
        "Behavioral cloning is a supervised learning approach where a model learns to imitate a driver's behavior directly from examples. You record camera frames while a human (or a reliable controller) drives and log the corresponding steering command at each frame. After preprocessing each frame (crop → color transform → blur → resize → normalize), a CNN (e.g., the NVIDIA end-to-end architecture) maps an image to a single continuous output: the steering angle. The model is trained to minimize the difference between its predicted angle and the logged angle (e.g., MSE or Huber loss). At runtime, the camera feed is fed through the same preprocessing and the network's predicted angle is used to control the vehicle—optionally with smoothing, speed governors, and safety checks. This bypasses explicit lane detection or planning and instead mimics the demonstrated driving policy."
      ],
      "metadata": {
        "id": "7XhyUDlRP1Fs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* [Installing and Importing Libraries](#scrollTo=NKw1owXNOP4i)\n",
        "\n",
        "* [Data Loading](#scrollTo=6acrZ1dAOM5A)\n",
        "\n",
        "* [Data Preprocessing](#scrollTo=uqsXizuEOIH9)\n",
        "\n",
        "* [Model Training](#scrollTo=AiOLWuMDN659)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "pbT5OThGQeJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and Importing Libraries"
      ],
      "metadata": {
        "id": "NKw1owXNOP4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reset to clean state and downloading dataset from GitHub"
      ],
      "metadata": {
        "id": "3H0UeExCOV0R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRS7JfK5yz4j"
      },
      "outputs": [],
      "source": [
        "!rm -rf track\n",
        "!rm nvidia_model.h5\n",
        "!git clone https://github.com/rslim087a/track\n",
        "!ls track"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing necessary libraries and dependencies"
      ],
      "metadata": {
        "id": "cibUqoY5Odql"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kE0RwSJHy0pi"
      },
      "outputs": [],
      "source": [
        "# Run this on fresh state\n",
        "!pip install -q tf2onnx onnx\n",
        "!pip3 install imgaug\n",
        "!pip3 install --upgrade --force-reinstall \"numpy==1.26.4\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing everything we'll need later"
      ],
      "metadata": {
        "id": "HfhzgkqmOn8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFwnq-G_0Avr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imgaug import augmenters as iaa\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import random\n",
        "import ntpath\n",
        "import tf2onnx\n",
        "import onnx\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading"
      ],
      "metadata": {
        "id": "6acrZ1dAOM5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset from `.csv` file to the memory"
      ],
      "metadata": {
        "id": "gylYpTGsO7H9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kzfoWrt0etD"
      },
      "outputs": [],
      "source": [
        "datadir = \"track\"\n",
        "columns = [\"center\", \"left\", \"right\", \"steering\", \"throttle\", \"reverse\", \"speed\"]\n",
        "\n",
        "data_df = pd.read_csv(os.path.join(datadir, \"driving_log.csv\"), names=columns)\n",
        "pd.set_option(\"display.max_colwidth\", None)\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-ZxceV71Zg6"
      },
      "outputs": [],
      "source": [
        "def path_leaf(path):\n",
        "    head, tail = ntpath.split(path)\n",
        "    return tail\n",
        "\n",
        "data_df[\"center\"] = data_df[\"center\"].apply(path_leaf)\n",
        "data_df[\"left\"] = data_df[\"left\"].apply(path_leaf)\n",
        "data_df[\"right\"] = data_df[\"right\"].apply(path_leaf)\n",
        "\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot33M95G3dRt"
      },
      "outputs": [],
      "source": [
        "num_bins = 25\n",
        "samples_per_bin = 400\n",
        "\n",
        "hist, bins = np.histogram(data_df[\"steering\"], num_bins)\n",
        "center = (bins[:-1] + bins[1:]) * 0.5\n",
        "\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(data_df[\"steering\"]), np.max(data_df[\"steering\"])), (samples_per_bin, samples_per_bin))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wRwarcS3x6P"
      },
      "outputs": [],
      "source": [
        "print(\"Total data:\", len(data_df))\n",
        "\n",
        "remove_list = []\n",
        "for j in range(num_bins):\n",
        "  list1_ = []\n",
        "  for i in range(len(data_df[\"steering\"])):\n",
        "    if data_df[\"steering\"][i] >= bins[j] and data_df[\"steering\"][i] <= bins[j + 1]:\n",
        "      list1_.append(i)\n",
        "  list1_ = shuffle(list1_)\n",
        "  list1_ = list1_[samples_per_bin:]\n",
        "  remove_list.extend(list1_)\n",
        "\n",
        "print(\"Removed:\", len(remove_list))\n",
        "data_df.drop(data_df.index[remove_list], inplace=True)\n",
        "print(\"Remaining:\", len(data_df))\n",
        "\n",
        "hist, _ = np.histogram(data_df[\"steering\"], num_bins)\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(data_df[\"steering\"]), np.max(data_df[\"steering\"])), (samples_per_bin, samples_per_bin))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdkWgOenAtSR"
      },
      "outputs": [],
      "source": [
        "print(\"Before:\", data_df.iloc[1])\n",
        "\n",
        "def load_img_steering(datadir, df):\n",
        "  image_path = []\n",
        "  steering = []\n",
        "\n",
        "  for i in range(len(data_df)):\n",
        "    indexed_data = data_df.iloc[i]\n",
        "    center, left, right = indexed_data[0], indexed_data[1], indexed_data[2]\n",
        "\n",
        "    # center\n",
        "    image_path.append(os.path.join(datadir, center.strip()))\n",
        "    steering.append(float(indexed_data[3]))\n",
        "\n",
        "    # left\n",
        "    image_path.append(os.path.join(datadir, left.strip()))\n",
        "    steering.append(float(indexed_data[3])+0.15)\n",
        "\n",
        "    #right\n",
        "    image_path.append(os.path.join(datadir, right.strip()))\n",
        "    steering.append(float(indexed_data[3])-0.15)\n",
        "\n",
        "  image_path = np.asarray(image_path)\n",
        "  steering = np.asarray(steering)\n",
        "  return image_path, steering\n",
        "\n",
        "image_path, steering = load_img_steering(datadir + \"/IMG\", data_df)\n",
        "\n",
        "print(len(image_path), len(steering))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training and testing subsets"
      ],
      "metadata": {
        "id": "6L8uBdVcOxdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkilDy6MESy3"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(image_path, steering, test_size=0.2, random_state=6)\n",
        "\n",
        "print(\"Training:\", len(X_train))\n",
        "print(\"Validation:\", len(X_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2MVXji8E6x-"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "axes[0].hist(y_train, bins=num_bins, width=0.05, color=\"blue\")\n",
        "axes[0].set_title(\"Training set\")\n",
        "axes[1].hist(y_valid, bins=num_bins, width=0.05, color=\"red\")\n",
        "axes[1].set_title(\"Validation set\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "uqsXizuEOIH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define zoom function"
      ],
      "metadata": {
        "id": "cke2E6oyPA05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Pwl72oQrbe"
      },
      "outputs": [],
      "source": [
        "def zoom(image):\n",
        "  zoom = iaa.Affine(scale=(1, 1.3))\n",
        "  image = zoom.augment_image(image)\n",
        "  return image\n",
        "\n",
        "image = image_path[random.randint(0, 1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "zoomed_image = zoom(original_image)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[1].imshow(zoomed_image)\n",
        "axes[1].set_title(\"Zoomed Image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define pan function"
      ],
      "metadata": {
        "id": "pAkHANfuPFBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKX26lz3SAl0"
      },
      "outputs": [],
      "source": [
        "def pan(image):\n",
        "  pan = iaa.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)})\n",
        "  image = pan.augment_image(image)\n",
        "  return image\n",
        "\n",
        "image = image_path[random.randint(0, 1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "panned_image = pan(original_image)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[1].imshow(panned_image)\n",
        "axes[1].set_title(\"Panned Image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define random brightness function"
      ],
      "metadata": {
        "id": "4KcPHc-8PGuB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqutW3zTShVJ"
      },
      "outputs": [],
      "source": [
        "def img_random_brightness(image):\n",
        "  brightness = iaa.Multiply((0.2, 1.2))\n",
        "  image = brightness.augment_image(image)\n",
        "  return image\n",
        "\n",
        "image = image_path[random.randint(0, 1000)]\n",
        "original_image = mpimg.imread(image)\n",
        "brightness_image = img_random_brightness(original_image)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[1].imshow(brightness_image)\n",
        "axes[1].set_title(\"Brightness Image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define random flip function"
      ],
      "metadata": {
        "id": "BuePftvKPJcV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVM1Uz2NThCr"
      },
      "outputs": [],
      "source": [
        "def img_random_flip(image, steering_angle):\n",
        "  image = cv2.flip(image, 1)\n",
        "  steering_angle = -steering_angle\n",
        "  return image, steering_angle\n",
        "\n",
        "idx = random.randint(0, 1000)\n",
        "image = image_path[idx]\n",
        "steering_angle = steering[idx]\n",
        "\n",
        "original_image = mpimg.imread(image)\n",
        "flipped_image, flipped_steering_angle = img_random_flip(original_image, steering_angle)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_image)\n",
        "axes[0].set_title(f\"Original Image (steering angle: {steering_angle})\")\n",
        "axes[1].imshow(flipped_image)\n",
        "axes[1].set_title(f\"Flipped Image (steering angle: {flipped_steering_angle})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Migrate those functions to one `random_augment` function"
      ],
      "metadata": {
        "id": "bVhMk3BrPLkg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ythymawNUwVz"
      },
      "outputs": [],
      "source": [
        "def random_augment(image, steering_angle):\n",
        "  image = mpimg.imread(image)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = pan(image)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = zoom(image)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image = img_random_brightness(image)\n",
        "  if np.random.rand() < 0.5:\n",
        "    image, steering_angle = img_random_flip(image, steering_angle)\n",
        "  return image, steering_angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwAJ5Xp8VLNw"
      },
      "outputs": [],
      "source": [
        "ncols = 2\n",
        "nrows = 10\n",
        "\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(15, 50))\n",
        "fig.tight_layout()\n",
        "\n",
        "for i in range(10):\n",
        "  idx = random.randint(0, len(image_path) - 1)\n",
        "  random_image = image_path[idx]\n",
        "  random_steering = steering[idx]\n",
        "\n",
        "  original_image = mpimg.imread(random_image)\n",
        "  augmented_image, steering_aug = random_augment(random_image, random_steering)\n",
        "\n",
        "  axes[i][0].imshow(original_image)\n",
        "  axes[i][0].set_title(f\"Original Image (steering angle: {random_steering})\")\n",
        "  axes[i][1].imshow(augmented_image)\n",
        "  axes[i][1].set_title(f\"Augmented Image (steering angle: {steering_aug})\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define preprocessing function for image"
      ],
      "metadata": {
        "id": "Zl3Ws3SbPVAR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WzFyASSFi9P"
      },
      "outputs": [],
      "source": [
        "def img_preprocess(img):\n",
        "  img = img[60:135,:,:]\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
        "  img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "  img = cv2.resize(img, (200, 66))\n",
        "  img = img / 255.0\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzVf85yLeGBh"
      },
      "outputs": [],
      "source": [
        "idx = random.randint(0, len(image_path) - 1)\n",
        "image = image_path[idx]\n",
        "original_img = mpimg.imread(image)\n",
        "preprocessed_img = img_preprocess(original_img)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "axes[0].imshow(original_img)\n",
        "axes[0].set_title(f\"Original Image {idx}\")\n",
        "axes[1].imshow(preprocessed_img)\n",
        "axes[1].set_title(f\"Preprocessed Image {idx}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define batch generator for more effecient training"
      ],
      "metadata": {
        "id": "KJALhZAwPX1t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OPEBx7ack9w"
      },
      "outputs": [],
      "source": [
        "def batch_generator(image_paths, steerings_ang, batch_size, is_training):\n",
        "  while True:\n",
        "    batch_img = []\n",
        "    batch_steering = []\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      random_index = random.randint(0, len(image_paths) - 1)\n",
        "\n",
        "      if is_training:\n",
        "        # Apply augmentation after reading the image\n",
        "        img, st = random_augment(image_paths[random_index], steerings_ang[random_index])\n",
        "      else:\n",
        "        img = mpimg.imread(image_paths[random_index])\n",
        "        st = steerings_ang[random_index]\n",
        "\n",
        "      # Preprocess the image\n",
        "      img = img_preprocess(img)\n",
        "      batch_img.append(img)\n",
        "      batch_steering.append(st)\n",
        "\n",
        "    yield (np.asarray(batch_img), np.asarray(batch_steering))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2bG6H_Cyk5N"
      },
      "outputs": [],
      "source": [
        "X_train_gen, y_train_gen = next(batch_generator(X_train, y_train, 1, 1))\n",
        "X_valid_gen, y_valid_gen = next(batch_generator(X_valid, y_valid, 1, 0))\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
        "fig.tight_layout()\n",
        "\n",
        "axes[0].imshow(X_train_gen[0])\n",
        "axes[0].set_title(f\"Training Image {y_train_gen[0]}\")\n",
        "axes[1].imshow(X_valid_gen[0])\n",
        "axes[1].set_title(f\"Validation Image {y_valid_gen[0]}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating and downloading calibration set for use to convert the model from `ONNX` to `HEF`"
      ],
      "metadata": {
        "id": "NxN_4O86Pe2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calibration_set, _ = next(batch_generator(X_valid, y_valid, batch_size=200, is_training=0))\n",
        "print(f\"Calibration set shape: {calibration_set.shape}\")"
      ],
      "metadata": {
        "id": "VcL9djZOk_ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calib_dir = \"calib_set\"\n",
        "if not os.path.exists(calib_dir):\n",
        "    os.makedirs(calib_dir)\n",
        "\n",
        "np.save(os.path.join(calib_dir, \"calibration_set.npy\"), calibration_set)"
      ],
      "metadata": {
        "id": "icVApxtLx7vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"calib_set/calibration_set.npy\")"
      ],
      "metadata": {
        "id": "-CEjuUU-ybc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "AiOLWuMDN659"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the model:"
      ],
      "metadata": {
        "id": "TMti9fvVPnxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXthgHRNkS97"
      },
      "outputs": [],
      "source": [
        "def nvidia_model() -> Sequential:\n",
        "  model = Sequential(name=\"nvidia_model\")\n",
        "  model.add(Input(shape=(66, 200, 3)))\n",
        "  model.add(Conv2D(24, (5, 5), strides=(2, 2), activation=\"elu\", name=\"conv_1\"))\n",
        "  model.add(Conv2D(36, (5, 5), strides=(2, 2), activation=\"elu\", name=\"conv_2\"))\n",
        "  model.add(Conv2D(48, (5, 5), strides=(2, 2), activation=\"elu\", name=\"conv_3\"))\n",
        "  model.add(Conv2D(64, (3, 3), activation=\"elu\", name=\"conv_4\"))\n",
        "  model.add(Conv2D(64, (3, 3), activation=\"elu\", name=\"conv_5\"))\n",
        "\n",
        "  model.add(Flatten(name=\"flat\"))\n",
        "\n",
        "  model.add(Dense(100, activation=\"elu\", name=\"fc_1\"))\n",
        "  model.add(Dense(50, activation=\"elu\", name=\"fc_2\"))\n",
        "  model.add(Dense(10, activation=\"elu\", name=\"fc_3\"))\n",
        "  model.add(Dense(1, name=\"fc_4\"))\n",
        "\n",
        "  optimizer = Adam(learning_rate=1e-3)\n",
        "  model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obRTWGCfNIVo"
      },
      "outputs": [],
      "source": [
        "model = nvidia_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin training"
      ],
      "metadata": {
        "id": "JefUn-zcPr61"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Q-oovmNkks"
      },
      "outputs": [],
      "source": [
        "history = model.fit(batch_generator(X_train, y_train, batch_size=100, is_training=1),\n",
        "                              steps_per_epoch=300,\n",
        "                              epochs=10,\n",
        "                              validation_data=batch_generator(X_valid, y_valid, batch_size=100, is_training=0),\n",
        "                              validation_steps=200,\n",
        "                              verbose=1,\n",
        "                              shuffle=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMa4a-Y2QVn3"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.legend([\"training\", \"validation\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the `.h5` model"
      ],
      "metadata": {
        "id": "xWMrk4qgPt1F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMLI0jsHSDJT"
      },
      "outputs": [],
      "source": [
        "model.save(\"nvidia_model.h5\")\n",
        "files.download(\"nvidia_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert it to `ONNX` and download it"
      ],
      "metadata": {
        "id": "AM3MnDj0PweR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e1d2929"
      },
      "source": [
        "onnx_model_path = \"nvidia_model.onnx\"\n",
        "tf2onnx.convert.from_keras(model, output_path=onnx_model_path)\n",
        "\n",
        "print(f\"Model converted and saved as {onnx_model_path}\")\n",
        "\n",
        "files.download(\"nvidia_model.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a448d2f1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NKw1owXNOP4i",
        "6acrZ1dAOM5A",
        "uqsXizuEOIH9",
        "AiOLWuMDN659"
      ],
      "mount_file_id": "1UJr2HGcNZ3_WrB3KiuxdYfKe5EGW2gc4",
      "authorship_tag": "ABX9TyMqhLjWwCTbeBtW+i5w3o3H",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}